{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "from skimage.io import imread_collection\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directories\n",
    "paths = ['images',\n",
    "            'images/1dim_uni_to_normal',\n",
    "                'images/1dim_uni_to_normal/gif',\n",
    "                'images/1dim_uni_to_normal/final',\n",
    "        ]\n",
    "\n",
    "paths_1 = ['images',\n",
    "            'images/1dim_norm(0,8)_to_normal',\n",
    "        ]\n",
    "\n",
    "paths_2 = ['images',\n",
    "            'images/1dim_norm(8,1)_to_normal',\n",
    "                'images/1dim_norm(8,1)_to_normal/gif',\n",
    "                'images/1dim_norm(8,1)_to_normal/final',\n",
    "        ]\n",
    "\n",
    "for i in paths:\n",
    "    if not os.path.exists(i):\n",
    "        os.makedirs(i)\n",
    "        \n",
    "for i in paths_1:\n",
    "    if not os.path.exists(i):\n",
    "        os.makedirs(i)\n",
    "\n",
    "for i in paths_2:\n",
    "    if not os.path.exists(i):\n",
    "        os.makedirs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(samples, dimensions=2):\n",
    "    return np.random.uniform(-1,1, (samples, dimensions))\n",
    "    #return np.random.normal(0,8, (samples,dimensions))\n",
    "    #return np.random.normal(8,1, (samples,dimensions))\n",
    "    \n",
    "def generate_data(samples, dimensions=2):\n",
    "    return np.random.normal(0,1, (samples, dimensions))\n",
    "\n",
    "# mapping (R,R)-->([-1,1], [-1,1])\n",
    "def generator(d, output_dim):\n",
    "    input_layer = layers.Input((d, ))\n",
    "    X = input_layer\n",
    "    # NN with 3 dense layers\n",
    "    for i in range(4):\n",
    "        X = layers.Dense(16)(X)\n",
    "        X = layers.LeakyReLU(0.1)(X)\n",
    "    output_layer = layers.Dense(output_dim)(X)\n",
    "    G = Model(input_layer, output_layer)\n",
    "    return G\n",
    "\n",
    "# mapping (R,R)-->[0,1]\n",
    "def discriminator(dim):\n",
    "    input_layer = layers.Input((dim,))\n",
    "    X = input_layer\n",
    "    # NN with 1 dense layer\n",
    "    for i in range(2):\n",
    "        X = layers.Dense(64)(X)\n",
    "        X = layers.LeakyReLU(0.1)(X)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid')(X)\n",
    "    D = Model(input_layer, output_layer)\n",
    "    D.compile(Adam(learning_rate = 0.002, beta_1 = 0.5),\n",
    "                     loss = 'binary_crossentropy',\n",
    "                     metrics = ['accuracy'])\n",
    "    return D\n",
    "\n",
    "# build GAN given a discriminator and a generator\n",
    "def GAN(G, D, d):\n",
    "    D.trainable = False\n",
    "    input_layer = layers.Input((d,))\n",
    "    X = G(input_layer)\n",
    "    output_layer = D(X)\n",
    "    GAN = Model(input_layer, output_layer)\n",
    "    GAN.compile(Adam(learning_rate = 0.001, beta_1 = 0.5),\n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = ['accuracy'])\n",
    "    return GAN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION\n",
    "\n",
    "def plots(G, D, step, D_loss, G_loss, filename):\n",
    "    file, ax = plt.subplots(2, 2, figsize=(8,8))\n",
    "    \n",
    "    # plot losses\n",
    "    ax[0,0].plot(step, G_loss, label='G loss', \n",
    "                    c='darkgreen', zorder=50, alpha=0.8,)\n",
    "    ax[0,0].plot(step, D_loss, label='D loss',\n",
    "                    c='darkblue', zorder=55, alpha=0.8,)\n",
    "    ax[0,0].set_xlim(0, max(max(step), batches)+5)\n",
    "    #ax[0,0].set_ylim(0.45, 1.0)\n",
    "    ax[0,0].set_xlabel('Epoch')\n",
    "    ax[0,0].legend(loc=1, frameon=False)\n",
    "    \n",
    "    # plot real and generated samples\n",
    "    fake_samples = G.predict(test_noise, batch_size=len(test_noise))\n",
    "    x_val = np.linspace(-3, 3, 301)\n",
    "    y_val = stats.norm(0,1).pdf(x_val)\n",
    "    ax[0,1].plot(x_val, y_val, color='k', label='real')\n",
    "    ax[0,1].fill_between(x_val, np.zeros(len(x_val)), y_val, color='k', alpha=0.6)\n",
    "    sns.kdeplot(fake_samples.flatten(), color='green', alpha=0.6, label='GAN', ax=ax[0,1], shade=True)\n",
    "    #ax[0,1].set_xlim(-3,3)\n",
    "    ax[0,1].legend(loc=1, frameon=False)\n",
    "    ax[0,1].set_xlabel('Sample Space')\n",
    "    ax[0,1].set_ylabel('Density')\n",
    "    \n",
    "    # plot confidence of the discriminator\n",
    "    confi = D.predict(grid_sample, batch_size=bs).flatten()\n",
    "    ax[1,0].plot(grid_sample.flatten(), confi, c='b')\n",
    "    lower, upper = -3, 3\n",
    "    for i in range(0, len(confi), 50):\n",
    "        if i==0:\n",
    "            continue\n",
    "        ax[1,0].plot([(i/len(confi))*(upper-lower) + lower, ]*2,\n",
    "                        [0, confi[i]], c='b')\n",
    "    ax[1,0].fill_between(grid_sample.flatten(), np.zeros(len(confi)), confi, color='b', alpha=0.6)\n",
    "    ax[1,0].set_xlabel('Sample Space')\n",
    "    ax[1,0].set_ylabel('Discriminator Value')\n",
    "    ax[1,0].set_xlim(lower,upper)\n",
    "    ax[1,0].set_ylim(0.0,1.0)\n",
    "        \n",
    "    # Q-Q Plot\n",
    "    qq = fake_samples.reshape(len(fake_samples,))\n",
    "    sm.qqplot(qq, line='45', markerfacecolor='cornflowerblue', markeredgecolor='cornflowerblue',  ax=ax[1,1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, transparent=True)\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# latent dimension\n",
    "d = 1\n",
    "\n",
    "# subsample for gif, set to zero if no gif wanted\n",
    "batches = 500\n",
    "\n",
    "# batch size\n",
    "bs = 512\n",
    "\n",
    "# plot frequency\n",
    "freq = 1\n",
    "\n",
    "test_noise = generate_noise(5000, d)\n",
    "test_samples = generate_data(5000, d)\n",
    "\n",
    "G = generator(d, 1)\n",
    "D = discriminator(1)\n",
    "GAN = GAN(G, D, d)\n",
    "\n",
    "grid_sample = np.linspace(-3, 3, 603)[1:-1].reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = []\n",
    "D_acc = []\n",
    "G_acc = []\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 499/500\n"
     ]
    }
   ],
   "source": [
    "# produce pictures for GIF\n",
    "\n",
    "for k in range(batches):\n",
    "    print(f'step: {k}/{batches}', end='\\r')\n",
    "    \n",
    "    # train discriminator\n",
    "    D.trainable = True\n",
    "    real_data = generate_data(bs//2,d)\n",
    "    fake_data = G.predict(generate_noise(bs//2, d), batch_size=bs//2)\n",
    "    data = np.concatenate((real_data, fake_data), axis=0)\n",
    "    \n",
    "    real_labels = np.ones((bs//2, 1))\n",
    "    fake_labels = np.zeros((bs//2,1))\n",
    "    labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
    "    \n",
    "    _D_loss, _D_acc = D.train_on_batch(data, labels)\n",
    "    \n",
    "    # train generator\n",
    "    D.trainable = False\n",
    "    noise = generate_noise(bs, d)\n",
    "    labels = np.ones((bs, 1))\n",
    "    _G_loss, _G_acc = GAN.train_on_batch(noise, labels)\n",
    "    \n",
    "    if k % freq == 0:\n",
    "        step.append(k)\n",
    "        D_loss.append(_D_loss)\n",
    "        G_loss.append(_G_loss)\n",
    "        plots(G=G, D=D, step=step, D_loss=D_loss, G_loss=G_loss,\n",
    "                #filename=f'images/1dim_uni_to_normal/gif/pic.{k:03d}.jpeg')\n",
    "                filename=f'images/1dim_norm(8,1)_to_normal/gif/pic.{k:03d}.jpeg')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make GIF\n",
    "#directory = 'images/1dim_uni_to_normal/gif/*.jpeg'\n",
    "directory = 'images/1dim_norm(8,1)_to_normal/gif/*.jpeg'\n",
    "images = imread_collection(directory)\n",
    "imageio.mimsave('images/1dim_norm(8,1)_to_normal/final/animation3.mp4', images, quality=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9999/10000\r"
     ]
    }
   ],
   "source": [
    "total_steps = 10000\n",
    "\n",
    "for k in range(batches, total_steps):\n",
    "#for k in range(6000, total_steps):\n",
    "    print(f'step: {k}/{total_steps}', end='\\r')\n",
    "    \n",
    "    # train discriminator\n",
    "    D.trainable = True\n",
    "    real_data = generate_data(bs//2,d)\n",
    "    fake_data = G.predict(generate_noise(bs//2, d), batch_size=bs//2)\n",
    "    data = np.concatenate((real_data, fake_data), axis=0)\n",
    "    \n",
    "    real_labels = np.ones((bs//2, 1))\n",
    "    fake_labels = np.zeros((bs//2,1))\n",
    "    labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
    "    \n",
    "    _D_loss, _D_acc = D.train_on_batch(data, labels)\n",
    "    \n",
    "    # train generator\n",
    "    D.trainable = False\n",
    "    noise = generate_noise(bs, d)\n",
    "    labels = np.ones((bs, 1))\n",
    "    _G_loss, _G_acc = GAN.train_on_batch(noise, labels)    \n",
    "    \n",
    "    if k % freq == 0:\n",
    "        step.append(k)\n",
    "        D_loss.append(_D_loss)\n",
    "        G_loss.append(_G_loss)\n",
    "        \n",
    "#plots(G=G, D=D, step=step, D_loss=D_loss, G_loss=G_loss, filename=f'images/1dim_uni_to_normal/final/pic.{k:03d}_4.png')\n",
    "#plots(G=G, D=D, step=step, D_loss=D_loss, G_loss=G_loss, filename=f'images/1dim_norm(0,8)_to_normal/pic.{k:03d}.png')\n",
    "plots(G=G, D=D, step=step, D_loss=D_loss, G_loss=G_loss, filename=f'images/1dim_norm(8,1)_to_normal/pic.{k:03d}_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
